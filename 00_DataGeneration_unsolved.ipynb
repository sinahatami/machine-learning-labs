{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Synthetic data generation\n",
    "\n",
    "This lab is about the generation of synthetic data.\n",
    "\n",
    "How to generate this data depends on the learning task: **classification** or **regression**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for regression problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to generate a D-dimensional dataset according to a linear regression problem, possibly affected by Gaussian noise.\n",
    "The use of the function is the following:\n",
    "\n",
    "```\n",
    "X, Y = linearRegrFunction(n, d, low_d, high_d, w, sigma_noise)\n",
    "```\n",
    "\n",
    "where\n",
    "- **n** is the number of samples to be generated\n",
    "- **d** is the size of each sample\n",
    "- **low_d** and **high_d** are arrays of, respectively, lower and upper bounds for the domain of the samples\n",
    "- **w** is an array with the linear function coefficients\n",
    "- **sigma_noise** is the standard deviation used to generate the Gaussian noise (with zero mean)\n",
    "- **X**, **Y**: d-dimensional samples (X) associated with 1-dimensional output (Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearRegrFunction(n, d, low_d, high_d, w, sigma_noise):\n",
    "   \n",
    "    X = np.zeros((n, d))\n",
    "    for i in range(0, d):\n",
    "        X[:,i] = np.random.uniform(low_d[i], high_d[i], size=n)\n",
    "    \n",
    "    gauss_noise = np.random.normal(0, sigma_noise, size=(n, 1))\n",
    "\n",
    "    Y = np.dot(X, w) + gauss_noise\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the data generator\n",
    "\n",
    "To start, generate a dataset of 1-dimensional input, for different values of `w` and no noise. <br> Pick the bounds of the domain that you prefer. \n",
    "<br> Let's consider the function `Y = wX` with `w=1` (the identity function), and then change the value of `w` as you prefer\n",
    "\n",
    "**Notice that since no noise is added, the obtained samples refer to the TRUE function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1\n",
    "w = np.array([1]).reshape(-1, d).T\n",
    "low_d = np.array([-100])\n",
    "high_d = np.array([100])\n",
    "\n",
    "n = 10 \n",
    "X, Y = linearRegrFunction(n, d, low_d, high_d, w, 0)\n",
    "\n",
    "\n",
    "plt.scatter(X, Y)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "\n",
    "# TRY WITH FURTHER SAMPLINGS, VISUALIZE THE OBTAINED POINTS ON THE SAME PLOT AND OBSERVE WHAT HAPPENS\n",
    "X1, Y1 = ...\n",
    "plt.scatter(X1, Y1)\n",
    "# WHAT HAPPENS WHEN YOU CHANGE THE AMOUNT OF POINTS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to add noise\n",
    "\n",
    "- Still considering the 1-dimensional case, fix the linear coefficients, the bounds, the number of samples and the amount of noise (e.g. `sigma_noise=3`) and generate multiple instances of the data.\n",
    "- Plot them together and observe the relationship between the different samples sets.\n",
    "- Also, generate the \"TRUE\" function and plot its samples as well. \n",
    "\n",
    "**Hint:** A sensible amount of noise depends on the `low_d` and `high_d` bounds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1\n",
    "w = np.array([1]).reshape(-1, D).transpose()\n",
    "low_D = np.array([-100])\n",
    "high_D = np.array([100])\n",
    "\n",
    "n = 30 \n",
    "sigma_noise = 10\n",
    "\n",
    "Xtrue, Ytrue = linearRegrFunction(100, D, low_D, high_D, w, 0)\n",
    "plt.plot(Xtrue, Ytrue,'-k')\n",
    "\n",
    "# GENERATE 4 DIFFERENT INSTANCES OF THE DATA KEEPING ALL THE PARAMETERS WITH THE SAME VALUE\n",
    "# VISUALIZE THE OBTAINED POINTS ON THE SAME PLOT AND OBSERVE WHAT HAPPENS\n",
    "\n",
    "Xd1, Yd1 = ...\n",
    "plt.scatter(...)\n",
    "\n",
    "#Xd2, Yd2 = ...\n",
    "#...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the amount of noise \n",
    "\n",
    "- Again on the 1-dimensional case, fix the parameters of the function, the bounds, the number of samples and compare the data obtained according to different amount of noise. <br>\n",
    "- Plot them together and observe the relationship between the different samples sets. <br>\n",
    "- Observe the difference as you change also the number of samples\n",
    "- Also, generate the \"TRUE\" function and plot its samples as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "D = 1\n",
    "w = np.array([1]).reshape(-1, D).transpose()\n",
    "\n",
    "low_D = np.array([-100])\n",
    "high_D = np.array([100])\n",
    "\n",
    "# Here we can compute the true function\n",
    "Xtrue, Ytrue = linearRegrFunction(100, D, low_D, high_D, w, 0)\n",
    "\n",
    "# Setup a plot in which the different sets can be shown and visually compared\n",
    "fig = plt.figure(figsize=(7,7)) \n",
    "ax0 = fig.add_subplot(2, 2, 1)\n",
    "ax1 = fig.add_subplot(2, 2, 2)\n",
    "ax2 = fig.add_subplot(2, 2, 3)\n",
    "ax3 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "Xd1, Yd1 = linearRegrFunction(n, D, low_D, high_D, w, sigma_noise=0.1)\n",
    "ax0.scatter(Xd1, Yd1, s=70, alpha=0.8)\n",
    "ax0.plot(Xtrue, Ytrue, c='r')\n",
    "ax0.set_title(\"Dataset 1\")\n",
    "\n",
    "# GENERATE 3 FURTHER INSTANCES OF THE DATA KEEPING THE SAME VALUE FOR ALL THE PARAMETERS BUT THE NOISE LEVEL\n",
    "# DATASET Xd2, Yd2 WITH sigma_noise = 5\n",
    "# DATASET Xd3, Yd3 WITH sigma_noise = 10\n",
    "# DATASET Xd4, Yd4 WITH sigma_noise = 25\n",
    "# VISUALIZE THE OBTAINED POINTS ON DIFFERENT SUBPLOTS\n",
    "\n",
    "# Fill here...\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the sample size \n",
    "\n",
    "- Let us consider a sample set with 2D input and 1D output, fix the parameters of the function, the bounds, the number of samples and compare the data obtained according to different amount of noise.\n",
    "- Plot them together and observe the relationship between the different samples sets.\n",
    "- Observe the difference as you change also the number of samples\n",
    "- Also, generate the \"TRUE\" function and plot its samples as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "n = 100\n",
    "D = 2\n",
    "w = np.array([0, 0]).reshape(-1, D).transpose()\n",
    "\n",
    "low_D = np.array([-100, -100])\n",
    "high_D = np.array([100, 100])\n",
    "\n",
    "# Here we can compute the true function\n",
    "Xtrue, Ytrue = linearRegrFunction(n, D, low_D, high_D, w, 0)\n",
    "\n",
    "# Setup a plot in which the different sets can be shown and visually compared\n",
    "fig = plt.figure(figsize=(10,10)) \n",
    "ax0 = fig.add_subplot(2, 2, 1, projection='3d')\n",
    "ax1 = fig.add_subplot(2, 2, 2, projection='3d')\n",
    "ax2 = fig.add_subplot(2, 2, 3, projection='3d')\n",
    "ax3 = fig.add_subplot(2, 2, 4, projection='3d')\n",
    "\n",
    "Xd1, Yd1 = linearRegrFunction(n, D, low_D, high_D, w, sigma_noise=0.1)\n",
    "ax0.scatter3D(Xd1[:,0], Xd1[:,1], Yd1, s=70, alpha=0.8)\n",
    "ax0.scatter3D(Xtrue[:,0], Xtrue[:,1], Ytrue, s=70, alpha=0.8)\n",
    "ax0.set_title(\"Dataset 1\")\n",
    "ax0.view_init(azim=30,elev=0)\n",
    "ax0.set_xlabel('X[:,0]')\n",
    "ax0.set_ylabel('X[:,1]')\n",
    "ax0.set_zlabel('Y')\n",
    "ax0.set_zlim([-80,80])\n",
    "\n",
    "Xd2, Yd2 = linearRegrFunction(n, D, low_D, high_D, w, sigma_noise=5)\n",
    "ax1.scatter3D(Xd2[:,0], Xd2[:,1], Yd2, s=70, alpha=0.8)\n",
    "ax1.scatter3D(Xtrue[:,0], Xtrue[:,1], Ytrue, s=70, alpha=0.8)\n",
    "ax1.set_title(\"Dataset 2\")\n",
    "ax1.view_init(azim=30,elev=0)\n",
    "ax1.set_xlabel('X[:,0]')\n",
    "ax1.set_ylabel('X[:,1]')\n",
    "ax1.set_zlabel('Y')\n",
    "ax1.set_zlim([-80,80])\n",
    "\n",
    "Xd3, Yd3 = linearRegrFunction(n, D, low_D, high_D, w, sigma_noise=10)\n",
    "ax2.scatter3D(Xd3[:,0], Xd3[:,1], Yd3, s=70, alpha=0.8)\n",
    "ax2.scatter3D(Xtrue[:,0], Xtrue[:,1], Ytrue, s=70, alpha=0.8)\n",
    "ax2.set_title(\"Dataset 3\")\n",
    "ax2.view_init(azim=30,elev=0)\n",
    "ax2.set_xlabel('X[:,0]')\n",
    "ax2.set_ylabel('X[:,1]')\n",
    "ax2.set_zlabel('Y')\n",
    "ax2.set_zlim([-80,80])\n",
    "\n",
    "Xd4, Yd4 = linearRegrFunction(n, D, low_D, high_D, w, sigma_noise=25)\n",
    "ax3.scatter3D(Xd4[:,0], Xd4[:,1], Yd4, s=70, alpha=0.8)\n",
    "ax3.scatter3D(Xtrue[:,0], Xtrue[:,1], Ytrue, s=70, alpha=0.8)\n",
    "ax3.set_title(\"Dataset 4\")\n",
    "ax3.view_init(azim=45,elev=0)\n",
    "ax3.set_xlabel('X[:,0]')\n",
    "ax3.set_ylabel('X[:,1]')\n",
    "ax3.set_zlabel('Y')\n",
    "ax3.set_zlim([-80,80])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating data for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the generation of 2D datasets for binary classification problems. We start by definying a function to generate datasets using 2D Gaussians.\n",
    "The use of the function is the following:\n",
    "##### X, Y = mixGauss(means, sigmas, n)\n",
    "where\n",
    "- <b>means</b> refers to the means of the Gaussian functions. It is in the form [m1,...mp], where p is the number of classes/Gaussian, and each mi is D-dimensional (e.g. D=2 for 2D data)  \n",
    "- <b>sigmas</b> refers to the standard deviations of the Gaussian functions. It is in the form [s1,...sp], where p is the number of classes/Gaussian (we assume standard deviation is the same for all dimensions)\n",
    "- <b>n</b> is the number of points for each class\n",
    "- <b>X</b>, <b>Y</b>: D-dimensional samples (X) associated with 1-dimensional output (Y). The latter is an array of labels, i.e. integers from the interval [0,p-1]\n",
    "<br>\n",
    "\n",
    "<b>EXAMPLE</b>: \n",
    "\n",
    "```X, Y = MixGauss([[0,0],[1,1]],[0.5, 0.25],1000)```\n",
    "\n",
    "generates a 2D dataset with two classes\n",
    "- the first one centered on (0,0) with standard deviation 0.5\n",
    "- the second one centered on (1,1) with standard deviation 0.25.\n",
    "Each class will contain 1000 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixGauss(means, sigmas, n):\n",
    "\n",
    "    means = np.array(means)\n",
    "    sigmas = np.array(sigmas)\n",
    "\n",
    "    d = means.shape[1]\n",
    "    num_classes = sigmas.size\n",
    "    data = np.full((n * num_classes, d), np.inf)\n",
    "    labels = np.zeros(n * num_classes)\n",
    "\n",
    "    for idx, sigma in enumerate(sigmas):\n",
    "        data[idx * n:(idx + 1) * n] = np.random.multivariate_normal(mean=means[idx], cov=np.eye(d) * sigmas[idx] ** 2,\n",
    "                                                                    size=n)\n",
    "        labels[idx * n:(idx + 1) * n] = idx \n",
    "        \n",
    "    if(num_classes == 2):\n",
    "        labels[labels==0] = -1\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the data generator\n",
    "Try and generate different datasets, by changing the parameters of the Gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup a plot in which the different sets can be shown and visually compared\n",
    "fig = plt.figure(figsize=(7,7)) \n",
    "ax0 = fig.add_subplot(2, 2, 1)\n",
    "ax1 = fig.add_subplot(2, 2, 2)\n",
    "ax2 = fig.add_subplot(2, 2, 3)\n",
    "ax3 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "# This is a Gaussian with center (mean) on the origin, and another one with center on the point (1,1).\n",
    "# Both of them have standard deviation equal to 0.25\n",
    "X1d, Y1d= mixGauss([[0,0], [1,1]], [0.25, 0.25], 100)\n",
    "ax0.set_title(\"Dataset 1\")\n",
    "ax0.scatter(X1d[:,0], X1d[:,1], s=70, c=Y1d, alpha=0.8)\n",
    "ax0.set_xlim((-3, 4))\n",
    "ax0.set_ylim((-2, 3))\n",
    "\n",
    "# GENERATE 3 FURTHER INSTANCES OF THE DATA KEEPING THE SAME AMOUNT \n",
    "#            OF POINTS BUT USING DIFFERENT PARAMETERS FOR THE GAUSSIAN\n",
    "# DATASET Xd2, Yd2 WITH centers in (0,0) and (3,2) and 0.25 as standard deviations for both\n",
    "# DATASET Xd3, Yd3 WITH centers in (0,0) and (3,2). The first Gaussian has standard deviation equal to 0.75,\n",
    "#                  the second one equal to 0.25\n",
    "# DATASET Xd4, Yd4 WITH centers in (0,0) and (1,1). The first Gaussian has standard deviation equal to 0.75,\n",
    "#                  the second one equal to 0.25\n",
    "# VISUALIZE THE OBTAINED POINTS ON DIFFERENT SUBPLOTS\n",
    "\n",
    "# Fill here...\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding noise to the binary classification dataset\n",
    "\n",
    "So far no noise have been added to the dataset. Let's add some using the function <b>flibLabels</b> that flips randomly selected labels of a binary classification problem. The use is the following\n",
    "\n",
    "##### Y_noisy = flipLabels(Y, perc)\n",
    "where\n",
    "- <b>Y</b> is the array of labels \n",
    "- <b>perc</b> is the percentage of labels to be flipped\n",
    "- <b>Y_noisy</b> is the array including the flipped labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipLabels(Y, perc):\n",
    "\n",
    "    if perc < 1 or perc > 100:\n",
    "        print(\"p should be a percentage value between 0 and 100.\")\n",
    "        return -1\n",
    "\n",
    "    if any(np.abs(Y) != 1):\n",
    "        print(\"The values of Ytr should be +1 or -1.\")\n",
    "        return -1\n",
    "\n",
    "    Y_noisy = np.copy(np.squeeze(Y))\n",
    "    if Y_noisy.ndim > 1:\n",
    "        print(\"Please supply a label array with only one dimension\")\n",
    "        return -1\n",
    "\n",
    "    n = Y_noisy.size\n",
    "    n_flips = int(np.floor(n * perc / 100))\n",
    "    idx_to_flip = np.random.choice(n, size=n_flips, replace=False)\n",
    "    Y_noisy[idx_to_flip] = -Y_noisy[idx_to_flip]\n",
    "\n",
    "    return Y_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with the noise in 2D datasets for binary classification\n",
    "Try and generate different datasets in which all parameters but the amount of noise are fixed. See what happens when you increase the percentage of flipped labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, Y1 = mixGauss([[0,0], [1,1]], [0.25, 0.25], 100)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7)) \n",
    "ax0 = fig.add_subplot(2, 2, 1)\n",
    "ax1 = fig.add_subplot(2, 2, 2)\n",
    "ax2 = fig.add_subplot(2, 2, 3)\n",
    "ax3 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "Y1_n0 = flipLabels(Y1, 5)\n",
    "ax0.set_title(\"Flipping 5% labels\")\n",
    "ax0.scatter(X1[:,0], X1[:,1], s=70, c=Y1_n0, alpha=0.8)\n",
    "\n",
    "\n",
    "# GENERATE 3 FURTHER INSTANCES OF THE DATA KEEPING THE SAME PARAMETERS FOR ALL BUT \n",
    "#       THE PERCENTAGE OF FLIPPED LABELS\n",
    "# TRY WITH 10%, 30% AND 50% OF FLIPPINGS \n",
    "# VISUALIZE THE OBTAINED POINTS ON DIFFERENT SUBPLOTS\n",
    "\n",
    "# Fill here...\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a more complex dataset with Gaussians\n",
    "\n",
    "Let's generate a more complex binary dataset. To do it, follow the instructions below:\n",
    "- Call the function <i>mixGauss</i> and produce a 2D dataset with 4 classes: the classes must be centered on the corners of the unit square (0,0), (0,1), (1,1), (1,0), and all of them have standard deviation equal to 0.25\n",
    "- Plot the obtained dataset\n",
    "- Manipulate the data to obtain a 2-class problem where data on opposite corners belong to the same class with labels +1 and -1. <b>Hint</b>: you can dot that using Ytr="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y4= mixGauss([[0,0], [0,1], [1,1], [1,0]], [0.2, 0.2, 0.2, 0.2], 100)\n",
    "\n",
    "fig = plt.figure(figsize=(10,7)) \n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax0.set_title(\"Dataset 1 - 4 classes\")\n",
    "ax0.scatter(X[:,0], X[:,1], s=70, c=Y4, alpha=0.8)\n",
    "\n",
    "Y2 = 2 * np.mod(Y4, 2) -1\n",
    "\n",
    "ax1.set_title(\"Dataset 2 - 2 classes\")\n",
    "ax1.scatter(X[:,0], X[:,1], s=70, c=Y2, alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A different way of generating binary classification problems: using a separator\n",
    "\n",
    "Let's explore different strategies to generate datasets for binary classification, based on the concept of separators. \n",
    "\n",
    "Observe what happens as you change the number of sampled points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200 # number of points per class\n",
    "D = 2 # dimension of the points\n",
    "\n",
    "# linear case\n",
    "m = 0.9\n",
    "q = 0\n",
    "\n",
    "# bounds (assume they are the same for all dimensions)\n",
    "low_D = -10\n",
    "high_D = 10\n",
    "\n",
    "X = np.zeros((n, D))\n",
    "Y = np.zeros(n)\n",
    "\n",
    "# sampling of the X\n",
    "for i in range(D):\n",
    "    X[:,i] = np.random.uniform(low_D, high_D, size=n)\n",
    "    \n",
    "# assigning the labels depending on the position of the sample with respect to the linear separator\n",
    "Y[X[:,1] - (X[:,0] * m + q) > 0] = 1 \n",
    "Y[Y==0] = -1\n",
    "\n",
    "# add some noise\n",
    "Yn = flipLabels(Y, 10)\n",
    "\n",
    "# plot the samples and the separator\n",
    "plt.title(\"Linear, 10% flipped labels\")\n",
    "plt.scatter(X[:,0], X[:,1], s=70, c=Yn, alpha=0.8)\n",
    "plt.plot(X[:,0], X[:,0] * m + q)\n",
    "plt.xlim((low_D, high_D))\n",
    "plt.ylim((low_D, high_D))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
