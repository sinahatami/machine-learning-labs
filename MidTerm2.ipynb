{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6024a2",
   "metadata": {},
   "source": [
    "# Mid-Term 2\n",
    "\n",
    "Sina Hatami (S5447389)\n",
    "\n",
    "### This mid-term assignment is composed by two exercise:\n",
    "#### 1. Non-linear synthetic data: compare Neural Networks, Kernel Regularized Least Squares (KRLS) with different kernels in solving non-linear problems\n",
    "#### 2. CIFAR-10 classification: given the dataset cifar10, implement a model to solve the classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d131775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a89a7",
   "metadata": {},
   "source": [
    "We provide here two functions to load data and compute the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75012523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name, d):\n",
    "    # name: file path\n",
    "    # d : dimension of input space\n",
    "    X, y = [], []\n",
    "    with open(\"{}\".format(name), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            splitted = line.split(\",\")\n",
    "            X.append(splitted[:-1])\n",
    "            y.append(splitted[-1])\n",
    "    X, y = np.asarray(X, dtype=np.float64).reshape(-1,d), np.asarray(y, dtype=np.float64).reshape(-1, 1)\n",
    "    return X, y\n",
    "\n",
    "def calc_err(Ypred, Ytrue):\n",
    "    return np.mean((Ypred-Ytrue)**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b54e5a9",
   "metadata": {},
   "source": [
    "## Assignment 1\n",
    "For each dataset provided, compare Neural Networks and kernel methods  in solving the problems associated with the provided datasets:\n",
    "- dataset 1: 700 points (500 for training and 200 for validation) in 5 dimensions\n",
    "- dataset 2: 4500 points (4000 for training and 500 for validation) in 5 dimensions\n",
    "- dataset 3: 150 points (100 for training and 50 for validation) in 5 dimensions\n",
    "- dataset 4: 2500 points (2000 for training and 500 for validation) in 10 dimensions\n",
    "\n",
    "Implement and compare performances (in MSE and time) of Neural Networks and KRLS with different kernels. For the Neural Networks, you can use the following architecture:\n",
    "- 2 hidden layers with 64 and 32 neurons activated with ReLU\n",
    "- optimizer: Adam with learning rate 0.01\n",
    "- batch-size: 32\n",
    "\n",
    "(However, in order to obtain better results, you can \"tune it\" for the different datasets (justifying changes))\n",
    "\n",
    "Note that since validation data are provided, in the fit function of the Neural Networks you should use `validation_data = (X_val, y_val)` instead of `validation_split=0.2`.\n",
    "\n",
    "Report in this notebooks your analysis.\n",
    "\n",
    "**Note that:** \n",
    "- For kernel methods, you should tune the parameters using cross-validation. Since validation data are provided you can use Hold-out CV.\n",
    "- Your model should perform well on validation data but it will be evaluated using a test set which is not provided!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d397cdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 10), (500, 10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data: Example\n",
    "X_tr, y_tr = load_dataset(\"./datasets/assignment_1/dataset_4_train\", 10)\n",
    "X_val, y_val = load_dataset(\"./datasets/assignment_1/dataset_4_val\", 10)\n",
    "\n",
    "X_tr.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a6ef2",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "In this task, we focus on solving the multiclass classification problem with CIFAR-10 dataset using a Neural Network. Follow our guidelines below for the structure of the network (but this time we are not giving precise information of the number of layers and neurons) \n",
    "\n",
    "As for the assignment n.1, report the performances i.e. training and validation accuracy (use the classification accuracy).\n",
    "\n",
    "**Note that:** Your model should perform well on validation data but it will be evaluated using a test set which is not provided!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540af804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_val, y_val) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206bb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize an image\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d66fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x_train, x_val = x_train / 255.0, x_val / 255.0\n",
    " \n",
    "# Convert labels in one-hot encoding (thus we can use the categorical-cross entropy)\n",
    "y_train = tf.one_hot(y_train, depth=10, dtype=tf.float64)\n",
    "y_val = tf.one_hot(y_val, depth=10, dtype=tf.float64)\n",
    "y_train = tf.squeeze(y_train)\n",
    "y_val = tf.squeeze(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93533dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a4f8c0",
   "metadata": {},
   "source": [
    "Implement here your model.\n",
    "\n",
    "**Hints:**\n",
    "- input data are images, thus a Convolutional NN might be more appropriate\n",
    "- the task is a multi-class classification problem thus the output layer should have N neurons with N number of classes and the activation function should be a soft-max\n",
    "- you can use the categorical cross-entropy (see [CategoricalCrossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy)) as loss to minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6ca71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert here your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
